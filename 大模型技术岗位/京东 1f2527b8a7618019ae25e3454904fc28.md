# 京东

创建时间: 2025年5月14日 00:18

# 面试题目

```markdown
1. 你拿到大模型业务需求会如何考虑？
2. 请介绍你认为最有成就的实习项目？
3. 为何广东人考虑来北京做算法工作？
4. 修改过损失函数吗？知道哪些有趣的损失函数？
5. 介绍一下LoRA微调原理：微调哪些层？常用训练参数设置（epoch、learning_rate等）？
6. LoRA微调能否有效注入领域知识？效果如何？
7. 了解大模型的位置编码吗？为什么必须使用位置编码？
8. 介绍决策树和信息熵？
9. 多轮对话数据的构成是什么？如何清洗？格式要求是什么？
10. 项目中使用了APO（Automatic Prompt Optimization），具体是如何实施的？是否有成效？
11. 介绍一下XGBoost，与GBDT相比有何不同？
12. 模型评估指标是什么？GSB如何细化？业务场景有哪些？
13. RAG是如何减少幻觉的？RAG有哪些幻觉？
14. 你对推荐算法有哪些了解？
15. 你对SFT有什么问题（长文本处理能力下降，通用知识能力下降）？
16. 微调中常见问题及解决方案？
17. 讲解LoRA原理，矩阵初始化，以及论文中LoRA的改进点？
18. 探讨外卖附近商家推荐功能的底层实现GEO数据结构？
19. 高并发场景下如何避免限流？大模型算力瓶颈的解决思路？
20. RAG切片实现方法如何设计和优化？
21. 多头自注意力机制是什么？有什么好处？为什么使用多头注意力机制？
22. Transformer中的前馈神经网络使用了什么激活函数？
23. 如何提高大模型输出的多样性？
24. 领域知识注入验证流程是怎样的？
25. 了解GBDT吗？基分类器使用什么？分类时也使用相同的基分类器吗？如何进行融合？
26. 逻辑回归是一个分类算法，它为什么叫逻辑回归？
27. 请介绍CNN？
28. ES与MySQL数据一致性方案及实时性优化方法？
29. Self-Attention的线性变换(QKV)为何必要？
30. 复读问题分析：原生模型复读不严重，微调后复读明显，原因何在？
31. 了解RHLF吗？RHLF模型有哪些？
32. 为什么将RAG与SFT结合使用？结合方式是怎样的？与普通SFT相比，效果是否有提升？
33. XGBoost在原理上相比GBDT有哪些改进？
34. 如何不使用乘法运算实现乘法功能？
35. 请说明图召回的训练方法及构造方式？
36. 如何防止LLM训练过拟合模型？
37. Softmax函数的作用机制是什么？
38. 你用过LoRa吗？LoRa的性能如何？
39. 我现在要做一个更拟人的客服智能体，你会如何做？
40. GLM是什么？
41. 大模型数据合成有哪些方法？
42. 随机森林的"随机"体现在何处？
43. 有哪些召回方法？
44. 如何解决用户分发与用户点击不一致的问题？
45. Embedding召回优化策略：如何提高召回效果和模型效率？
46. 介绍人类反馈强化学习DPO、PPO和KTO？
47. 了解自博弈的强化学习吗？
48. 了解llama3吗？讲一下其改进之处？
49. 如何自实现RPC框架？Java通信方式与Reactor模型是怎样的？
50. RAG切片工程优化内容是什么？
51. 幻觉抑制技术体系是什么？
52. 梯度消失是什么？如何缓解梯度消失？
53. 大模型7B使用KV缓存进行推理时，显存消耗如何计算？
54. 优化器考点：Loss除以10和学习率除以10有什么区别？
55. 如何初始化lora的A和B（高斯分布或0），这两个可以互换吗？
56. text2sql的评估指标是什么？使用的什么数据？怎么训练的？为什么最后选择llama2-13b模型？为什么不做全量FT？
57. Adam和AdamW的区别是什么？
58. Lora的秩为什么可以较低？
59. 了解BERT的结构吗？说一下？
60. 了解旋转位置编码吗？介绍一下？
61. RAG的效果如何评估？
62. Self-Attention中的Softmax为何必要？
63. QKV变换的必要性？
64. SVM原理是什么？如何找到最优线性分类器？支持向量是什么？
65. 如何解决大模型幻觉问题？
66. 如何仅使用random(0,7)实现random(0,9)？
67. 请说明MHA，MQA和GQA的区别？
68. 预训练的步骤是什么？
69. 介绍一下双塔召回和图召回？
70. 为什么分类问题使用交叉熵而不是MSE？
71. 32B模型调用需要多少张卡？max_token有数量限制吗？
72. 多轮对话中如何进行query重写？
73. 了解强化学习吗？请简述RLHF的流程。已经完成了SFT，为什么还需要进行RL？
74. 做过RAG调参吗？调参的基本流程是什么？
75. MHA公式有优化吗？GQA是如何实现的？
76. 如何缓解KV缓存问题在不同模型结构中出现的情况？
77. 手撕代码：判断字符串是否为旋转数组？
78. 手撕搜索推荐系统？
79. 手撕代码：手动实现平方根使用数学分析中的牛顿法？
80. 面试内容为：实现链表两两反转算法？
```

# 面试经验

```markdown
1. 请介绍您的优点和缺点？
2. 面试全程20分钟，后20分钟为技术报告等相关闲聊？
3. 4月22日一面和二面当场通过？
4. 希望下周能接到HR面试通知结束痛苦的暑期实习等待？
5. 总结：考察较深入，涉及模型post-training和通信核心业务，后者完全不会？
6. 面试官很好，团队主要研发医药领域的大模型，资源充足？
7. 京东实习待遇好，技术岗位月薪10000元，异地有1500元住房补贴？
8. 提及自己在上次面试后查看了一些搜索推广相关的内容？
9. 遇到过各种类型的面试官，如直接让写模型代码、读论文、做LeetCode题、讨论项目或纯粹写代码的？
10. 标准面试流程通常是自我介绍、项目经验、基础知识、LeetCode题和反问环节？
11. 面试时长1.5小时，感觉不错？
12. 核心组面试共三轮，包括两轮算法面和一轮HR面？
13. 算法面考查八股文和代码，项目细节也被问到？
14. 整体流程两周结束，offer发放迅速？
15. 总结下来，最难的是阿里的面试，很多问题都没有答出来？
16. 二面难度会更大，面试官会更多地提问场景题？
17. 美团和京东的一面都进行得很顺利？
18. 一面面试官详细询问了项目细节，还提出了很多开放性问题？
19. 京东面试没有手撕代码环节，两个面试主要询问项目实习经历，未涉及八股文问题？
20. 复读问题的归因分析？
21. 这种问题最难回答，有时不知如何让面试官满意？
22. 临时准备，也有成效？
23. 很多人只知道准备八股文和LeetCode，但自我介绍和项目介绍最重要？
```