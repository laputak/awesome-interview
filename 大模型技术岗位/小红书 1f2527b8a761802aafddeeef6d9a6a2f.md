# 小红书

创建时间: 2025年5月14日 00:18

# 面试题目

```markdown
1. 先围绕项目展开，穿插概念理解。  
2. 对项目有较多理解，请介绍一篇论文，时间为二十分钟。  
3. 八股文很多，还有一些视觉方面的问题。  
4. 你觉得最大的难点是什么？  
5. 询问实习相关信息。  
6. 我的项目使用大模型实现text2sql，xhs项目组也在开发此应用，我们围绕这方面讨论了许多细节。  
7. 面试主要讨论实习经验，较少涉及理论知识考察，重点在于实习经历和代码题。建议大家多练习代码题。  
8. 突然遇到一道智力题，有些迷茫，以后需要多准备一些题解。  
9. 结合LLM与推荐系统时会遇到哪些问题？  
10. Graph分布式训练如何实现，如何进行分布式存储？  
11. 算法题1：有n个灯泡，初始全灭。执行n轮操作，第k轮反转所有k的倍数位置灯泡状态。问n轮后有多少灯泡亮着。  
12. 代码：输入三个等长序列，根据pos和neg规则返回满足要求的下标对。难度适中，ACM格式，面试官未提供测试用例，重点是代码思路正确。  
13. 如何理解online和offline以及on policy和off policy？  
14. RAG有哪些缺陷？  
15. 请介绍LLaMa的关键技术点。  
16. 如何提高模型的泛化能力？  
17. 最近一段实习的具体工作，能否详述五分钟？  
18. R1为什么推理能力强？  
19. 小红书和抖音的冷启动处理机制有什么区别？  
20. 算法题2：给定数组，每次取一个数K，移除所有k-1和k+1，如何取使所取数之和最大，最大值是多少？  
21. 了解视觉中的Transformer吗？了解ViT吗？  
22. 为什么VLm能加快大模型推理速度？  
23. 算法题：给定一个整数数组和一个整数k，找到数组中和为k的连续子数组个数。  
24. 算法题：Ic115，不同子序列。  
25. 如何优化大模型检索过程以减少延迟并提高效率？  
26. SFT和RLHF各自适用于什么场景，它们各有什么优缺点？  
27. 总关注量越高越好吗，直接优化总关注量指标会出现什么问题？  
28. 大模型参数量为何设计为7B、13B、33B、65B等数值？  
29. 新模型的指标提升了多少？  
30. 结合LLM与推荐系统时会遇到哪些问题？  
31. 其他离线算法，如Simpo，其具体物理含义是什么？  
32. LLaMA1、LLaMA2和LLaMA3的异同是什么？  
33. 手撕岛屿数量问题。  
34. Transformer和LSTM+Attention相比，主要的改进点是什么？  
35. 你对推荐系统的整个流程了解哪些部分？  
36. 考虑过利用线上用户行为进行微调吗？  
37. 如何保证大模型输出内容的一致性？  
38. 请介绍Transformer的架构。  
39. 代码题：先提供一段字符串代码，再进行优化，考察Python基础。  
40. 在将LLM与推荐系统结合落地时遇到了哪些问题？  
41. 面试内容为：prompt能否激发模型能力？  
42. 了解打分样本空间分布与精排不一致的问题吗？精排对粗排返回的样本进行排序，而粗排则对召回的样本打分。  
43. embedding是如何获得的？  
44. 第二道题是实现计算器，这是一道难题。  
45. 提示工程的主要方法有哪些？  
46. 追问项目细节30分钟。  
47. 全量微调是什么意思？  
48. BERT中MASK是否满足独立性假设？有何改进方案？  
49. 用户推荐通常关注哪些指标？  
50. 面试内容为：实现全排列算法。  
51. 大模型生成内容的评测有哪些方式，具体如何进行？  
52. 面试内容为：类似LC 879 盈利计划类型 但场景发生变化。  
53. 求最大子数组和。  
54. DPO是如何从PPO推导出来的？具体的数学推导比较复杂。  
55. LLM与推荐结合是否有可落地的方案？  
56. 长prompt在zero shot和sft中的影响是什么？  
57. 抖音和小红书的推荐系统在算法上有什么差别？  
58. 有两个硬币，一个全是正面，一个一正一反。拿到一个发现是正面，那么另一个是正面的概率是多少？  
59. LLM与推荐结合是否有可落地方案？  
60. 如何处理大量用户的节点问题？  
61. LLM如何处理用户历史行为序列？  
62. LLM对推荐有哪些帮助？  
63. RLHF训练过程是怎样的？  
64. 你知道哪些自回归模型和自编码模型？它们各自的优缺点是什么？  
65. grpo ppo的具体思路是什么？  
66. 模型规模和网络规模。  
67. DPO、PPO、GRO有什么区别？  
68. 直接优化总关注量可能导致大量刷关注的用户增加，如何从模型角度解决此问题？  
69. 面试内容为：手撕对角线矩阵。  
70. 论文：询问了两篇已发表和一篇在投论文，其中两篇为NLP方向，一篇为大模型推理加速方向。重点讨论了NLP方向的两篇论文，需全面讲解并随时回答问题。需准备充分，如同刚完成实验并撰写论文。还简要介绍了SFT八股和训练中显存优化方法（并行+ZeRO），但未深入探讨。问题针对性强，可能与论文和部门业务契合。  
71. 请说明DeepSeek R1的训练流程和原理。  
72. 目前long-context中的主流方法有哪些？  
73. Multi-Head公式推导为什么不增加复杂度？  
74. DPO如何解决RLHF的问题？  
75. 模型为什么有效果？  
76. 请简单介绍sAm。  
77. LLM与推荐结合有哪些可落地的方案？  
78. 如何保证多智能体协同效果？  
79. 大模型加速方法？介绍Flash Attention。  
80. LLM对推荐算法有何帮助？  
81. Transformer与LSTM+Attention相比，主要改进点是什么？  
82. SFT和强化学习的优缺点是什么？分别适用于哪些场景？  
83. 召回、粗排和精排要解决什么问题？请选择一个最熟悉的环节，讲解其未来的迭代方向。  
84. 小红书和抖音的冷启动处理机制有何区别？  
85. 为什么业务上会关注总关注数这个指标？  
86. 给链表头结点，按升序排列并返回排序后的链表。  
87. 请详细说明Deepspeed的工作机制。  
88. 如何保证链路一致性？  
89. 模型的标签是什么？  
90. 如何让大模型基于问题和上下文生成高质量回答？  
91. 您是否接触过GPU中的底层算子？  
92. 平时使用哪些大模型训练和推理框架？  
93. 抖音和小红书的冷启动处理机制有什么区别？  
94. 大模型训练何时需要预训练？何时需要SFT？何时需要DPO？  
95. BERT和GPT的区别是什么，它们是如何训练的？  
96. 抖音和小红书的推荐系统有何差别，从算法角度谈谈。  
97. 如何在不使用额外空间的情况下交换两个数？  
98. 手撕三维动态规划。  
99. 两道手撕题目为：m个数组之间的最大距离和三数之和。  
100. DPO与PPO的区别是什么？  
101. 为什么VLLM能加快大模型推理速度？  
102. 算法题2：给定数组，每次取出一个数k，然后去掉数组中所有k-1和k+1，如何取使所取数之和最大，最大值是多少？  
103. LLM如何处理用户历史行为序列？
```

# 面试经验

```markdown
1. 小红书面试官很温和，全程主要针对我的简历项目提问，已收到录用通知。  
2. 面试结束后5分钟内挂断电话，不拖延，小红书门槛较高。  
3. 面试流程：四轮面试（三轮技术面试，一轮HR面试），谈薪并发放录用通知，流程推进迅速，面试体验良好。  
4. 面试系统连接不稳定，面试官声音有些嘈杂。  
5. 这是我遇到过的最难的手撕算法面试题，提示很久才完成。  
6. 虽然面试官两次都在面试前几个小时因临时开会更改了面试时间，让人有些不适，但面试官们都很友好，给我提供了很多建议，包括如何包装项目、梳理项目逻辑以及选择暑期实习等。这也是面试的收获之一。  
7. 两轮面试体验不错，技术面试已结束，等待结果。  
8. 二面是我遇到过的最难的推荐面试，比抖音推荐面试难许多。感觉回答还算OK，最后一题在提示下做出来了。  
9. 后续与leader深入探讨了方向和未来工作，认为应用加AI比纯研究AI更落地。研究AI很有价值，这里仅从普通码农角度出发。  
10. 这是我遇到过的最难的推荐面试，比抖音推荐面试难很多，感觉回答还算可以，最后一题在提示下做出来了。  
11. 请进行三分钟的自我介绍。  
12. 需要达到刚完成实验并撰写文章后对内容了然于胸的状态。
```