# 小米

创建时间: 2025年5月14日 00:22

# 面试题目

```markdown
1. 项目的主要目标是什么？
2. 面试主要询问了简历中的项目经验
3. 请深入介绍一下你的项目
4. 你在论文中有哪些创新想法？
5. for循环的底层实现原理是什么？
6. 请谈谈你对模型量化的理解
7. 请介绍QLoRA方法，包括4位权重量化、LoRA矩阵初始化为零矩阵等细节
8. 你常用哪些大模型？能列举一些常用的大模型吗？
9. LeetCode 244题：设计哈希表
10. 请介绍PPO算法
11. 如何优化数据库检索延迟问题？
12. 算法题：股票最大利润交易（动态规划解法）、全排列问题
13. 在xx项目中如何解决遮挡导致的视角歧义问题？
14. 如何设计跨模态注意力机制？请举例说明
15. 考察了一些数学基础知识
16. 在视觉Transformer中，如何处理非均匀采样的3D点云数据？可以谈谈Patch Embedding的改进
17. 混合精度微调具体混合使用了哪些精度？
18. 请介绍GRPO算法及其优势
19. 请介绍常见的损失函数并手写实现
20. 你用GRPO复现过实验吗？R1和R1zero的区别是什么？
21. 如何将FP16精度转换为int4并最小化误差？具体实现过程是怎样的？
22. GAE(广义优势估计)有什么缺点？
23. Python字典的底层实现原理是什么？
24. 模型量化参数如何选择？如何保证量化后的模型效果？
25. 请介绍YOLOv7的网络结构和评估标准mAP
26. 迭代器与生成器有什么区别？
27. 强化学习中，基于值的学习和基于策略的学习有什么区别？
28. 请介绍beam search算法
29. 请介绍注意力机制的原理
30. 动态规划题：计算将word1转换为word2所需的最少操作数
31. QLoRA是如何实现的？
32. 你了解LoRA技术吗？
33. DPO和PPO有什么区别？DPO的优化目标是什么？
34. 如果加入雷达点云作为第三模态，该如何调整对齐策略？
35. 为什么PPO算法要使用优势函数评估，而不是直接使用reward？
36. 注意力机制的计算复杂度及改进方法有哪些？包括MHA、MQA、GQA等，最好能提供代码示例
37. 算法题：搜索旋转排序数组、合并有序数组
38. LeetCode 347题：TopK问题
39. GRPO算法是什么？
40. 有哪些常用的数据平滑方法？
41. 如何实现冻结矩阵的反量化？
42. GRPO存在方差问题，在什么场景下适合应用GRPO？SFT需要如何处理才能让GRPO强化学习微调效果更好？
43. 算法题：找出数组中的第k大数
44. 关于focal loss，面试官说与交叉熵无关，是他的理解有误还是我的专业能力不足？
45. 在文生3D任务中，如何将Stable Diffusion的输出与NeRF/SDF等3D重建方法结合？
46. 请介绍你设计的课题流程，以及这样设计的创新点
47. 在3D语义分割任务中，如何选择MIoU和Chamfer Distance指标？
48. 请解释COT(思维链提示)和Instruction Tuning的理解
49. 优势函数有什么优势？
50. 请解释MHA(多头注意力)的原理
51. 你对比过不同3D表征方式对多模态融合的影响吗？
52. 请写出MIOU的计算公式
53. 算法题：实现数组topk取值，尽可能用多种方法(堆排序、快排等)
54. 在视频生成场景下，时序信息对齐与空间对齐哪个更重要？为什么？
55. 请解释tensor操作中view和reshape方法的区别
56. Transformer相比之前的模型为什么有显著提升？
57. 文本摘要有哪些实现方法？
58. 请比较GRPO、PPO、DPO的区别
59. 文本审核常用的评估指标有哪些？
60. GRPO中的Group如何选择？
61. BERT后续有哪些改进工作？改进了哪些方面？
62. 请手写自注意力机制的代码或描述实现过程
63. 青蛙跳台阶问题：一次可以跳1或2级，求跳上n级台阶有多少种跳法
64. Q-Learning和PPO是什么算法？
65. 如何看待工作中的琐碎任务和纪律性考察？
66. RAG应用的主要难点是什么？
67. XGBoost和LightGBM有什么区别和联系？
68. RNN有什么用途？LSTM做了哪些改进？
69. 在分类任务中，BERT和GPT+prompt哪种效果更好？为什么？
70. 你对知识蒸馏了解多少？有哪些改进？为什么大模型蒸馏成小模型比直接使用小模型效果好？
71. 如何解决prompt的泛化性问题？
72. 请描述一个文本生成图像的模型框架
73. 算法题：反转链表
74. 你做过BERT项目，请介绍一下BERT和Transformer的区别
75. 问了很多基础的机器学习算法问题
76. 自注意力和普通注意力有什么区别？注意力机制中的K、Q、V分别代表什么？请简述自注意力流程
77. 为什么PPO要使用优势函数评估，而不是直接用reward？
78. 基于给定数据实现一个分类器
79. 有哪些分词算法？训练模型的常见策略有哪些？
80. 如果有高质量的论文和项目，基础问题会问得较少，主要深入讨论论文和项目，只简单提及几个基础问题
```

# 面试经验

```markdown
1. 面试开始时双方互相做了自我介绍
2. 回答问题时有些犹豫不决
3. 面试官形象温和，是典型的理工男风格
4. 第三面的面试官态度很温柔
5. 大模型岗位面试场景题很多，比八股文难，容易被问住，提前准备题目很重要
6. 整个面试过程感觉很有压力。作为没有实习经历的在校生，感到有些尴尬
7. 小米的秋招面试是第一场，很大程度上缓解了前期的焦虑，面完后紧张感减轻不少
8. 投递小米大模型算法岗，听说日常实习是两轮面试，二面后以为没戏，结果收到三面通知
9. 投了美团北斗计划和普通暑期实习，北斗计划三个志愿都没过简历关。暑期实习先面了一轮，换部门后又面一轮，第二次面试难度较高持续一小时，自我感觉还行但最终没通过
10. 作为非科班出身，没怎么练过算法题，所以选择了放弃
11. 很担心会不会还有第三轮面试
12. 面试官进来时表情不太好，看起来不太想面试的样子
13. 在小米官网投递一周后收到一面邀请，一面结束两小时收到二面通知。二面和面试官聊得不错，问了我入职时间和实习时长后表示欢迎来实习，说HR会联系发offer。刚面完还没收到确认
14. 我先做了两分钟自我介绍，然后面试官介绍了他们团队的工作内容
15. 最后面试官问到岗时间和实习时长，然后进入反问环节
16. 感觉准备得再好也不如岗位匹配度重要
```