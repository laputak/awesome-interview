# 阿里巴巴

创建时间: 2025年5月14日 00:15

# 面试题目

```markdown
1. 面试主要围绕论文、项目和算法题展开，包含大量灵活的场景问题
2. 面试以场景题为主
3. 最近参加阿里淘天集团算法岗面试，首次遇到开场就要求手写代码的情况
4. 阿里面试难度较高，直接以编程题开始
5. 深入追问论文和项目细节
6. 询问论文实验的硬件配置（显卡型号）、模型规模和训练框架
7. 在Embedding训练中如何保留空间语义同时去除用户隐私信息
8. 计算attention时节省显存的策略（如样本拼接计算）
9. 路网拓扑嵌入（Graph Embedding）的实现方法
10. 腾讯实习项目的RAG评估指标（准确率、召回率及线上指标）
11. 介绍LoRA微调方法
12. 多模态大模型中text和image的融合方式
13. QLoRA与LoRA的区别及各自优缺点
14. 显存不足时的常见优化方案
15. 大模型显存估算方法、管理策略及多机多卡经验（询问使用框架）
16. 端侧ASR模型的语音纠错实现（如"使馆"转"四环"）
17. zero2和zero3并行策略的区别
18. VLM中vision encoder的计算效率测试情况
19. 并行计算时跨机器参数获取机制
20. 多模态能力接入LLM的方法
21. 介绍zero技术
22. 动态加载策略（如按地域分区加载模型参数）
23. 门控机制解决的问题背景
24. 多头注意力对计算量和参数量的影响
25. 确认实习是否使用MegatronLM框架
26. 阿里通义实验室手撕题：20分钟内实现随机tensor的forward计算
27. LoRA引入后的参数量计算及适用层选择
28. 时间窗口切片策略（高峰时段差异化处理）
29. 微调技术对比（p-tuning/lora与传统fine-tuning）
30. 上下文长度扩展方法
31. 训练过拟合的成因、判断方法和解决方案
32. llama2位置编码类型及不同位置编码对比
33. Encoder和Decoder的应用场景区分
34. Zero技术的三个阶段详解
35. Deepspeed使用经验及分布式训练效率优化
36. LoRA的矩阵初始化原理（AB矩阵设计）
37. GRPO/DPO/PPO区别、reward model必要性及R1冷启动作用
38. CoT（Chain-of-Thought）设计方法
39. SFT调参实践经验
40. Transformer核心原理考察
41. 实习中模型优化方案的设计难点
42. KL散度与交叉熵的异同
43. 损失函数缩放影响及多目标损失计算
44. llama2采用的注意力机制类型
45. 基于用户反馈（如路线投诉）的检索模型更新方法
46. 显存不足解决方案（gradient checkpointing/accumulation原理）
47. llama3汉化工作要点
48. LoRA参数调整经验
49. Transformer架构描述
50. LLM中强化学习应用了解程度
51. DeepSeek的版本改进点
52. 4卡All Reduce操作的通信量计算（单次通信量x）
53. 数据处理方法及质量评估手段
54. 分布式训练的并行策略分类
55. 手写带mask矩阵的特殊损失函数及rope实现
56. 梯度下降法求平方根、岛屿面积计算
57. 大模型幻觉问题解决方案
58. 大模型方向高频知识点
59. LLM重复生成问题的缓解方法
60. 多头注意力机制解释
61. encoder-only/decoder-only/encoder-decoder的适用场景对比
62. 机器学习中√k的含义理解
63. 主流大模型loss函数对比
64. GQA（Grouped Query Attention）概念
65. Transformer对前人工作的借鉴点
66. 多头注意力的作用价值
67. Transformer归一化方式选择原因（LN vs BN）
68. VLM中信息完备性与幻觉的权衡
69. DeepSeek架构创新点（r1/r1zero/v3）及fp8无损实现
70. 最新强化学习改进方法
71. 模型蒸馏技术（如BERT到TinyBERT）
72. Qwen使用体验及最大改进点
73. SFT模型的loss计算方法和有效区域控制
74. 模型幻觉的常规解决手段
75. 手写分组注意力实现
76. 对Transformer的掌握程度评估
77. 算法题：合并K个升序链表
78. langchain的核心结构和任务链处理优势
79. Deepspeed与Megatron的差异及各自优势
80. 二维attention mask的显存优化（一维替代方案）
81. 地图图像理解技术（拥堵识别、施工标志检测等）
82. 半精度训练原理、优势及实际挑战
83. MoE架构兴起原因及其相比Dense的优势
84. VLM的扩展定律
85. in-context learning的采样策略（随机vs检索）
86. KV缓存原理
87. 算法题：乘积最大子数组（贪心解法）
88. 位置编码实现方式
89. 注意力计算公式
90. 高德场景的数据闭环设计（实时数据联动）
91. RLHF步骤熟悉度
92. 需要掌握多种模型的注意力机制和位置编码
93. 端云协同设计方案（车载设备资源优化）
94. 地理数据安全处理（敏感信息过滤）
```

# 面试经验

```markdown
1. 面试官认可技术能力，一面指出了项目中的几个不足之处
2. 实习待遇优厚，且有转正机会
3. 参加了淘天的面试，首先进行了自我介绍
4. 第三次面试是与部门高管的交流，他对大模型的理解非常深入，让我受益匪浅
5. 阿里的面试考察非常细致，面试官对我不了解的问题表现得很宽容
6. 三面的场景题回答不够理想，最终未能通过面试
7. 最近面试了淘天搜推智能产品事业部的大模型算法岗，整体体验不错。问题难度适中，面试官态度友善，遇到难题时会适当引导，氛围比较轻松
8. 9月30日通过了一面，国庆假期后安排了二面
9. 整体面试体验很好
10. 建议提前了解不同公司的业务侧重点，做好针对性准备
```