# 美团

创建时间: 2025年5月14日 00:16

# 面试题目

```markdown
1. 自我介绍环节
2. 选择一段CV算法实习经历进行分享
3. 讨论图片质量分析项目，探讨与大模型应用的契合度
4. 交流多模态大模型在质量分析中的实际应用（不展开具体技术细节）
5. 第一个部门面试仅关注项目经历，未涉及理论知识
6. 团队协作中遇到方案分歧时的处理方式
7. 分享美团多模态大模型推荐算法面试全记录（重点关注RL应用）
8. 比赛经历中的最大收获
9. 面试难度评估及团队业务介绍（智能客服用药问答场景）
10. 首次暑期实习代码题经历（需面试官提示优化）
11. 搜索推荐排序部门的技术规划（大模型融合）
12. 美团面试特点：项目细节导向，需手写公式
13. 第二个部门的面试完全基于简历提问
14. 对比Qwen、LLaVA、DeepSeek-VL等视觉语言模型
15. R1流程中模型选择策略（V3参考模型处理80万数据）
16. 数据集多样性和复杂度的保障方法
17. 合并两个有序链表的算法实现
18. LoRA基本原理及参数初始化方法解析
19. 线上效果评估指标
20. DeepSeek核心技术介绍（GRPO和MLA）
21. 显存占用的影响因素分析
22. LoRA的优缺点及改进方向
23. R1在SFT阶段冷启动的目的
24. 论文研究方向脉络梳理
25. 多模态大模型优化方案（对标GPT4V，OCR增强）
26. 当前使用模型的参数量级
27. 编辑距离算法题
28. 高分辨率文档处理方案
29. 数据集自动构建与标注流程
30. GLM模型架构辨析（prefix LM vs casual model）
31. 文档大模型的整合策略（独立or融合）
32. 多头注意力机制原理及mask作用
33. 实习/项目机会咨询
34. 寻找数组中第k大数字的算法
35. text2sql任务中LLM与传统方法的对比
36. RAG评价指标体系
37. Manus代理的实现原理探讨
38. 搜索旋转排序数组（LeetCode热题100）
39. 实习经历和项目经验陈述
40. 提升Llama系列中文能力的方法
41. AUC指标解释
42. 函数调用模块介绍
43. LSTM三门机制说明（输入/遗忘/输出门）
44. 分层指令调优技术
45. 数据规模及划分对模型稳定性的影响
46. 实习岗位偏好调查
47. AGI发展阶段理论（DeepMind观点）
48. 最长递增子序列算法
49. 图像预训练与提示微调工作流程
50. 传统机器学习算法掌握情况（如决策树）
51. 多模态对齐方法对比（CLIP/BLIP/BLIP2）
52. 项目问题复盘及成果评估
53. 多轮对话设计开放题（目标强化/损失计算/历史记忆）
54. 资源充足情况下的最优架构选择
55. OCR文档大模型应用
56. DeepSpeed三阶段解析
57. 个人研究兴趣方向
58. 目标检测模型训练部署全流程
59. Llama使用RMSNorm的原因及有效性分析
60. 大模型灾难性遗忘解决方案
61. 长文本外推方法综述（除线性外推外）
62. CPC和ESSM模型的改进点
63. 14B模型显存需求估算
64. GRPO技术详解及冷启动机制
65. 训练数据获取与生成数据质量评估
66. 实习项目流程、重难点和创新点
67. 召回后重排序的必要性
68. RAG实施难点分析
69. 大型模型使用体验对比
70. GRPO与DPO的对比分析
71. 代理技术在美团及其他场景的应用展望
72. MLA与LoRA的区别及DeepSpeed的突破
73. LoRA参数高效性原理
74. 合理评估指标设计（OpenAI压缩理论）
75. DPO改进方向
76. 自注意力系数sqrt(d)的数学依据
77. 神经网络初始化一致性影响
78. Transformer结构详解
79. 智能机器人工作流设计
80. LightGBM掌握程度
81. 指定科研工作深度描述
82. 训练中的跷跷板现象观察
83. 位置编码公式及优势分析
84. Llama2到Llama3的位置编码改进
85. RAG框架模块组成
86. 大模型激活函数特点（如GELU）
87. 推荐指标扩展（NDCG/MAP等）
88. DeepSeek-R1模型介绍
89. Flamingo与BLIP2架构对比
90. 微调方法掌握情况（P-tuning/prompt tuning）
91. 搜索二维矩阵（LeetCode原题）
92. 大模型应用工作流全链路
93. Transformer归一化选择原因（LayerNorm vs RMSNorm）
94. Llama2对比Baichuan/ChatGLM的优势
95. DPO与PPO的区别
96. 实验室近期课题
97. 模型对垂类场景的理解评估
98. 大模型驱动浏览器操作的实现路径
99. 最长递增子序列长度求解
100. 不准确查询的改进方案
101. LLM硬件控制与指令解析
102. 职业选择考量因素
103. PPO/DPO/GRPO对比及R1数据处理
104. 大模型工作原理概述
105. R1流程详解
106. 药物说明书RAG场景设计
107. 时间复杂度优化方法
108. LoRA技术理解
109. MLA推理速度优势分析
110. 概率论与矩阵分析基础
111. MoE架构采用原因
112. 滑动窗口最大值算法
113. 数据集评估内容设计
114. Transformer位置编码原理（含RoPE）
115. 长文本模型与RAG的替代关系
116. 大模型显存占用分析
117. 医疗语言模型结合点
118. 模型迭代情况说明
119. RAG实现方案
120. 升序数组绝对值去重（双指针法）
121. LayerNorm公式及有效性分析
122. Instruction tuning关键因素
123. Self-attention机制及改进方向
124. 多分辨率图片处理方案
125. 交叉熵公式
126. LN与BN的区别
127. AdamW优化器原理
128. MoE架构特点
129. 字符串相加编程题
130. 过拟合解决方案
131. 浮点精度对比（BF16/FP16/FP32）
132. 最大连续子序列和代码题误解案例
133. R1的MLA实现KV-Cache优化
134. 强化学习输出长度变化原因
135. 多模态位置编码方案
136. 中序遍历迭代实现
137. 梯度问题改进方案
138. GAE计算与批量关系
139. FFN层知识存储机制
140. 深度学习损失函数盘点
141. 强化学习最新进展
142. Transformer架构复述
143. Agent方向进展评价
144. MoE优化版本信息
145. 多头注意力调试经验
146. 向量数据库索引构建
147. LoRA初始化策略分析
148. XGBoost相对GBDT优势
149. 非下游指标引导优化
150. Uplift项目全流程
151. 领域知识融合方法
152. TTS技术实现方案
153. KV缓存与Flash注意力
154. Agent反问能力实现
155. 幻觉减少与RAG准确性保障
```

# 面试经验

```markdown
1. 迄今为止体验最好的HR面试，HR给了很多职业发展建议，聊了1个小时
2. 每次面试前都会有些紧张，听说公司很看重面试评价
3. 美团是所有面试公司中体验最好的，无论是日常实习还是校招，面试官都很友善，不会施加太大压力且很有耐心
4. 面试官直接进入技术问题，没有过多寒暄
5. 总结：面试难度适中，但需要关注前沿研究，算法岗需要多读论文
6. 一面结束后15分钟就收到二面通知，流程推进很快
7. 日常实习只有两轮面试，每轮40-60分钟，2天后HR会直接电话沟通offer
8. 请分享一次突破自己舒适区的经历
9. 毕业后计划选择互联网工作还是继续读博？
10. 请列举三个自己的优点和三个缺点
11. 遇到最难合作的同事时是如何处理的
12. 请分享本科保研的经历
13. 未来计划从哪些方面提升自己
```